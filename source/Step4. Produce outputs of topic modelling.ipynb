{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../coronavirus_twenty_years_of_research/technical_validation/'\n",
    "k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH + \"NMF_topic_modelling_results({}clusters).csv\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning title and abstract\n",
    "\n",
    "def removeWhiteSpaces(text):\n",
    "    # 1) Remove newline, etc. (into Space)\n",
    "    redun_lines = [\"\\n\", chr(13)]\n",
    "    for line in redun_lines:\n",
    "        text = text.replace(line, \" \")\n",
    "    # 2) Remove >1 conseq Spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # 3) other whitespaces* (incl 1,2?)\n",
    "    text = \" \".join(re.split(r\"\\s+\", text))\n",
    "    #  https://www.delftstack.com/howto/python/how-to-remove-whitespace-in-a-string/\n",
    "    #  \\s for any whitespaces (incl new line!?): incl collection [ \\t\\n\\r\\f\\v]\n",
    "    return text.strip()\n",
    "\n",
    "def clear_tags(dataObj, tags_only=False):\n",
    "    \"\"\"\n",
    "    Cleaning - remove tags, URLs, special characters\n",
    "    \"\"\"\n",
    "    dataObj = dataObj.replace(\"\\\\n\", '')\n",
    "    dataObj = dataObj.replace(\"['\", '')\n",
    "    dataObj = dataObj.replace(\"']\", '')\n",
    "    \n",
    "    # Del Tag + Content (sub-titles):   <jats:title content-type=\"abstract-subheading\">Purpose</jats:title>\n",
    "    redun_tags = ['<jats:title>', '<title>']\n",
    "    for tag in redun_tags:\n",
    "        start = dataObj.find(tag[:-1])\n",
    "        while start != -1:\n",
    "            end = dataObj.find(\"</\" + tag[1:-2], start)  # length 13      (excl last 2: for </tag   >\n",
    "            if end != -1: dataObj = dataObj.replace(dataObj[start:end + 13], \" \")\n",
    "            start = dataObj.find(tag[:-1], start + 5)  # NEXT start (SKIP current - *if prev without end)\n",
    "\n",
    "    # Del ALL Tags <....>    # redun_tags = [\"<p>\", \"<jats:p>\", \"<jats:sec>\", \"<sec>\", \"<jats:italic>\", \"<jats:bold>\", \"<jats:p id=\"\"p1\"\">\"]\n",
    "    dataObj = re.sub('<[^<]+?>', ' ', dataObj)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Del URLs\n",
    "    re_url = 'https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|info)/' + '[a-z0-9.\\-]'\n",
    "    dataObj = re.sub(re_url, '', dataObj)\n",
    "\n",
    "    if not tags_only:\n",
    "        ### Del Symbols\n",
    "        dataObj = re.sub('[&;]\\d+;*', ' ', dataObj)  # [0-9] -> \\d, [;] -> ;\n",
    "        dataObj = re.sub('&[A-Z]{4}', ' ', dataObj)\n",
    "        dataObj = re.sub('&\\W{2,10};', ' ', dataObj)  # [\\W] -> \\W\n",
    "        dataObj = re.sub('&#\\d{2,4};', ' ', dataObj)\n",
    "        redun = [\"amp\", \";lt\", \";gt\", \"&lt\", \"&gt\", \";p\", \"div\", \"&#x0D;\", \"ldquo\", \"rdquo\", \" \", \" \", \" \", \"#160\", \"/p\", \";\"]\n",
    "        for substr in redun:\n",
    "            dataObj = dataObj.replace(substr, \" \")\n",
    "\n",
    "    return removeWhiteSpaces(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning ISSN, container-title\n",
    "\n",
    "def cleaning_columns(x):\n",
    "    if type(x) != float:\n",
    "        values = eval(x)\n",
    "        cleaned_values = []\n",
    "        for v in values:\n",
    "            cleaned_values.append(v)\n",
    "        return cleaned_values\n",
    "    else:\n",
    "        return 'nan'\n",
    "\n",
    "def cleaning_container_title(x):\n",
    "    if type(x) != float:\n",
    "        values = eval(x)\n",
    "        return values[-1]\n",
    "    else:\n",
    "        return 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning created, published, and last-updated\n",
    "def cleaning_date_columns(date):\n",
    "    try:\n",
    "        row_value = ast.literal_eval(date)\n",
    "        date = str(row_value['date-parts'])\n",
    "        cleaned_date = date.replace('[', '')\n",
    "        cleaned_date = cleaned_date.replace(']', '')\n",
    "        cleaned_date = cleaned_date.replace(', ', '-')\n",
    "        return cleaned_date\n",
    "    except:\n",
    "        return date\n",
    "\n",
    "def cleaning_last_updated(date):\n",
    "    try:\n",
    "        row_value = ast.literal_eval(date)\n",
    "        return row_value['$date'][:10]\n",
    "    except:\n",
    "        return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning link\n",
    "\n",
    "def cleaning_link_text(text):\n",
    "    try:\n",
    "        row_value = ast.literal_eval(text)\n",
    "        return row_value[0]['URL']\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning author\n",
    "\n",
    "def clean_author_list(x):\n",
    "    if type(x) != float:\n",
    "        authors = eval(x)\n",
    "        cleaned_authors = []\n",
    "        for person in authors:\n",
    "            if 'given' in person:\n",
    "                cleaned_authors.append(person['given'] + \" \" + person['family'])\n",
    "        return cleaned_authors\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning funder\n",
    "\n",
    "def clean_funder(x):\n",
    "    if type(x) != float:\n",
    "        funders = eval(x)\n",
    "        cleaned_funder = []\n",
    "        for funder in funders:\n",
    "            if 'name' in funder:\n",
    "                cleaned_funder.append(funder['name'] )\n",
    "        return cleaned_funder\n",
    "    else:\n",
    "        return 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning cluster-coefficient\n",
    "\n",
    "def clean_topic_correlation(x):\n",
    "    correlations = eval(x)\n",
    "    correlations = { \"cluster\"+str(k): v for k, v in correlations.items() }\n",
    "    return list(correlations.items())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created'] = df['created'].apply(lambda x: cleaning_date_columns(x)) \n",
    "df['journal'] = df['container-title'].apply(lambda x:cleaning_container_title(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x:clear_tags(str(x)))\n",
    "df['abstract'] = df['abstract'].apply(lambda x:clear_tags(str(x)))\n",
    "df['ISSN'] = df['ISSN'].apply(lambda x:cleaning_columns(x)) \n",
    "df['journal'] = df['container-title'].apply(lambda x:cleaning_container_title(x)) \n",
    "df.drop(columns=['container-title'], inplace=True)\n",
    "df['created'] = df['created'].apply(lambda x: cleaning_date_columns(x)) \n",
    "df['published'] = df['published'].apply(lambda x: cleaning_date_columns(x)) \n",
    "df['link'] = df['link'].apply(lambda x: cleaning_link_text(x)) \n",
    "df['author'] = df['author'].apply(lambda x: clean_author_list(x)) \n",
    "df['funder'] = df['funder'].apply(lambda x: clean_funder(x)) \n",
    "df['cluster-coefficient'] = df['cluster-coefficient'].apply(lambda x: clean_topic_correlation(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df\n",
    "sorted_df = df.sort_values(by=['created'], inplace=False) # sort by date\n",
    "sorted_df['created'] = sorted_df['created'].astype(str)\n",
    "sorted_df['published'] = sorted_df['published'].astype(str)\n",
    "sorted_df = sorted_df[['DOI', 'title', 'abstract', \n",
    "                      'author', 'created', 'published',\n",
    "                      'URL', 'link', \"ISSN\", 'journal', 'source', 'type', \n",
    "                      'publisher', 'funder', 'cluster', 'cluster-coefficient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_2020_df = sorted_df.loc[sorted_df['created'] < '2020-01'].reset_index(drop=True)\n",
    "after_2020_df = sorted_df.loc[sorted_df['created'] > '2020-01'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie JSON pre 2020\n",
    "dict_records = before_2020_df.to_dict('records')\n",
    "\n",
    "for c in range(k):\n",
    "    OUTPUT_PATH = '../coronavirus_twenty_years_of_research/clusters/cluster{}/pre_2020/'.format(str(c))\n",
    "    tmp_df = before_2020_df.loc[before_2020_df['cluster'] == c].reset_index(drop=True)\n",
    "    for i, r in tmp_df.iterrows():\n",
    "        doi = tmp_df['DOI'].iloc[i]\n",
    "        doi = doi.replace('/', '-')\n",
    "        if not os.path.exists(OUTPUT_PATH):\n",
    "            os.makedirs(OUTPUT_PATH) \n",
    "        with open(OUTPUT_PATH+'{}.json'.format(doi), 'w') as f:\n",
    "            json.dump(dict_records[i], f,ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie JSON post 2020\n",
    "for c in range(k):\n",
    "    tmp_df = after_2020_df.loc[after_2020_df['cluster'] == c].reset_index(drop=True)\n",
    "    for Y in range(2020, 2029):\n",
    "        for M in range(1, 13):\n",
    "            OUTPUT_PATH = '../coronavirus_twenty_years_of_research/clusters/cluster{}/{}-{}/'.format(str(c), Y, M)\n",
    "            sub_tmp_df = tmp_df.loc[tmp_df['created'].str.contains(\"{}-{}\".format(Y, M))] # select data by date\n",
    "            if len(sub_tmp_df) == 0:continue\n",
    "            sub_tmp_df = sub_tmp_df.reset_index(drop=True) # reset index\n",
    "\n",
    "            dict_records = sub_tmp_df.to_dict('records')\n",
    "            #print(\"Cluster#{}:{}-{} has {} of articles\".format(str(c), Y, M, len(sub_tmp_df)))\n",
    "            \n",
    "            for i, r in sub_tmp_df.iterrows():\n",
    "                doi = sub_tmp_df['DOI'].iloc[i]\n",
    "                doi = doi.replace('/', '-')\n",
    "                if not os.path.exists(OUTPUT_PATH):\n",
    "                    os.makedirs(OUTPUT_PATH)          \n",
    "                with open(OUTPUT_PATH+'{}.json'.format(doi), 'w') as f:\n",
    "                    json.dump(dict_records[i], f,ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_venv",
   "language": "python",
   "name": "covid_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
