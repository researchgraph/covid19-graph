{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Word2vec Model with COVID-19 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihoonwoo/opt/anaconda3/envs/covid_venv/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyparameters for generating word2vec model\n",
    "\n",
    "- vector_size (int, optional) – Dimensionality of the word vectors.\n",
    "- window (int, optional) – Maximum distance between the current and predicted word within a sentence.\n",
    "- min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
    "- sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "- negative (int, optional) – If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). If set to 0, no negative sampling is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 100\n",
    "WINDOW_SIZE = 5\n",
    "MIN_COUNT = 20\n",
    "SG = 1\n",
    "NEGATIVE = 20\n",
    "SAVE_DIR = '../Data/covid_word2vec/'\n",
    "INPUT_DIR = '../Data/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470382, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read input data\n",
    "input_df = pd.read_csv(INPUT_DIR + \"preprocessed_data.tsv\", sep='\\t', encoding='utf-8')\n",
    "input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(df):\n",
    "    token_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        token_list.append(row['text'].split(' '))\n",
    "    training_docs = np.asarray(token_list)\n",
    "\n",
    "    return training_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihoonwoo/opt/anaconda3/envs/covid_venv/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"covid_\" + str(VECTOR_SIZE) + \"d.txt\"\n",
    "model_filename = \"covid_\" + str(VECTOR_SIZE) + \"d.model\"\n",
    "\n",
    "model = Word2Vec(corpus, \n",
    "                 vector_size=VECTOR_SIZE, \n",
    "                 window=WINDOW_SIZE, \n",
    "                 min_count=MIN_COUNT, \n",
    "                 sg=SG, \n",
    "                 negative=NEGATIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.wv.save_word2vec_format(SAVE_DIR + \"/\" + filename, binary=False)\n",
    "model.save(SAVE_DIR + \"/\" + model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained word2vec model\n",
    "model_filename = \"covid_\" + str(VECTOR_SIZE) + \"d.model\"\n",
    "wv_model = Word2Vec.load(SAVE_DIR + \"/\" + model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size to be embedded: 32451\n",
      "vaccination exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('vaccine', 0.8372259736061096),\n",
       " ('immunization', 0.8313582539558411),\n",
       " ('booster', 0.8280298709869385),\n",
       " ('two_dose', 0.8003955483436584),\n",
       " ('third_dose', 0.779162585735321),\n",
       " ('vaccinate', 0.751685380935669),\n",
       " ('pfizer_biontech', 0.7484267950057983),\n",
       " ('coronavac', 0.7439802289009094),\n",
       " ('post_vaccination', 0.7432931661605835),\n",
       " ('one_dose', 0.7317822575569153)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of vocabs in the worv2vec model \n",
    "print(\"vocabulary size to be embedded: {0}\".format(len(model.wv)))\n",
    "\n",
    "# verify model with exist word\n",
    "word = 'vaccination'\n",
    "if word in wv_model.wv:\n",
    "    print(word + ' exist')\n",
    "# print the most similar words\n",
    "wv_model.wv.most_similar(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_venv",
   "language": "python",
   "name": "covid_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
