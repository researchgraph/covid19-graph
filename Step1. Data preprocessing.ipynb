{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Documents Data Preprocessing\n",
    "\n",
    "This Jupyter notebook demonstrates how to preprocess COVID-19 article data by using python code. Data preprocessing aims to make data to be useful for analysis, which contains removing duplications, non-English documents, cleaning text, and reformatting data table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '../data/original data/covid-json/'\n",
    "OUTPUT_PATH = '../data/outputs/articles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405248, 71) (107277, 71) (86873, 68)\n"
     ]
    }
   ],
   "source": [
    "# Use pandas library to convert json to dataframe\n",
    "\n",
    "df1 = pd.read_json(INPUT_PATH+\"covid_19.json\")\n",
    "df2 = pd.read_json(INPUT_PATH+\"covid19.json\")\n",
    "df3 = pd.read_json(INPUT_PATH+\"sars_cov_2.json\")\n",
    "print(df1.shape, df2.shape, df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480297, 71)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the converted dataframes\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "covid_df = pd.concat(frames)\n",
    "\n",
    "# Remove duplicated articles by '_id'\n",
    "covid_df.drop_duplicates(subset=['_id'], keep='first', inplace=True)\n",
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 480297 entries, 0 to 86870\n",
      "Data columns (total 71 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   _id                     480297 non-null  object \n",
      " 1   abstract                245584 non-null  object \n",
      " 2   URL                     480297 non-null  object \n",
      " 3   member                  480112 non-null  float64\n",
      " 4   score                   480297 non-null  int64  \n",
      " 5   created                 480297 non-null  object \n",
      " 6   update-policy           147550 non-null  object \n",
      " 7   license                 259697 non-null  object \n",
      " 8   ISSN                    389019 non-null  object \n",
      " 9   container-title         416929 non-null  object \n",
      " 10  issued                  480297 non-null  object \n",
      " 11  prefix                  480297 non-null  float64\n",
      " 12  reference-count         480297 non-null  int64  \n",
      " 13  indexed                 480297 non-null  object \n",
      " 14  author                  463376 non-null  object \n",
      " 15  DOI                     480297 non-null  object \n",
      " 16  is-referenced-by-count  480297 non-null  int64  \n",
      " 17  published               477558 non-null  object \n",
      " 18  published-print         250692 non-null  object \n",
      " 19  alternative-id          200937 non-null  object \n",
      " 20  subject                 254422 non-null  object \n",
      " 21  published-online        282759 non-null  object \n",
      " 22  content-domain          480297 non-null  object \n",
      " 23  reference               261143 non-null  object \n",
      " 24  title                   480297 non-null  object \n",
      " 25  link                    360437 non-null  object \n",
      " 26  source                  480297 non-null  object \n",
      " 27  type                    480208 non-null  object \n",
      " 28  publisher               480112 non-null  object \n",
      " 29  volume                  322417 non-null  object \n",
      " 30  references-count        480297 non-null  int64  \n",
      " 31  issn-type               389019 non-null  object \n",
      " 32  deposited               480297 non-null  object \n",
      " 33  page                    306559 non-null  object \n",
      " 34  short-container-title   341175 non-null  object \n",
      " 35  import-source           480297 non-null  object \n",
      " 36  last-updated            480297 non-null  object \n",
      " 37  issue                   279963 non-null  object \n",
      " 38  journal-issue           279965 non-null  object \n",
      " 39  published-other         22338 non-null   object \n",
      " 40  funder                  50842 non-null   object \n",
      " 41  assertion               106069 non-null  object \n",
      " 42  posted                  51641 non-null   object \n",
      " 43  subtype                 51641 non-null   object \n",
      " 44  accepted                40362 non-null   object \n",
      " 45  group-title             49222 non-null   object \n",
      " 46  institution             36889 non-null   object \n",
      " 47  editor                  9487 non-null    object \n",
      " 48  original-title          11071 non-null   object \n",
      " 49  subtitle                11334 non-null   object \n",
      " 50  archive                 9371 non-null    object \n",
      " 51  relation                21923 non-null   object \n",
      " 52  article-number          33713 non-null   object \n",
      " 53  event                   13740 non-null   object \n",
      " 54  update-to               2232 non-null    object \n",
      " 55  clinical-trial-number   354 non-null     object \n",
      " 56  isbn-type               8146 non-null    object \n",
      " 57  ISBN                    8146 non-null    object \n",
      " 58  edition-number          4576 non-null    object \n",
      " 59  publisher-location      10064 non-null   object \n",
      " 60  chair                   92 non-null      object \n",
      " 61  degree                  229 non-null     object \n",
      " 62  approved                376 non-null     object \n",
      " 63  translator              24 non-null      object \n",
      " 64  pubmed-abstract         2940 non-null    object \n",
      " 65  content-created         2416 non-null    object \n",
      " 66  description             4157 non-null    object \n",
      " 67  review                  2485 non-null    object \n",
      " 68  standards-body          33 non-null      object \n",
      " 69  content-updated         63 non-null      object \n",
      " 70  short-title             14 non-null      object \n",
      "dtypes: float64(2), int64(4), object(65)\n",
      "memory usage: 263.8+ MB\n"
     ]
    }
   ],
   "source": [
    "covid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_formatting(date_str):\n",
    "    date_str = str(date_str).replace(\"'\", '\"')\n",
    "    date = json.loads(date_str)\n",
    "    row_value = date['date-parts']\n",
    "    year = row_value[0][0]\n",
    "    month = row_value[0][1]\n",
    "    day = row_value[0][2]\n",
    "    return \"{}/{}/{}\".format(month, day, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54965</th>\n",
       "      <td>10.1016/0168-1702(95)00046-s</td>\n",
       "      <td>{'date-parts': [[2002, 7, 25]], 'date-time': '...</td>\n",
       "      <td>2002-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49291</th>\n",
       "      <td>10.1016/s0168-1702(01)00432-4</td>\n",
       "      <td>{'date-parts': [[2002, 7, 25]], 'date-time': '...</td>\n",
       "      <td>2002-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40764</th>\n",
       "      <td>10.1016/s0929-693x(01)00696-0</td>\n",
       "      <td>{'date-parts': [[2002, 7, 25]], 'date-time': '...</td>\n",
       "      <td>2002-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56200</th>\n",
       "      <td>10.1016/s0165-2478(97)87550-5</td>\n",
       "      <td>{'date-parts': [[2002, 7, 25]], 'date-time': '...</td>\n",
       "      <td>2002-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31251</th>\n",
       "      <td>10.1016/s0966-842x(00)89018-6</td>\n",
       "      <td>{'date-parts': [[2002, 7, 25]], 'date-time': '...</td>\n",
       "      <td>2002-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344664</th>\n",
       "      <td>10.1016/j.ijid.2021.12.146</td>\n",
       "      <td>{'date-parts': [[2022, 2, 28]], 'date-time': '...</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344665</th>\n",
       "      <td>10.36106/ijar/7000796</td>\n",
       "      <td>{'date-parts': [[2022, 2, 28]], 'date-time': '...</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344666</th>\n",
       "      <td>10.1016/j.rceng.2021.11.005</td>\n",
       "      <td>{'date-parts': [[2022, 2, 28]], 'date-time': '...</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344668</th>\n",
       "      <td>10.22541/au.164608823.39016270/v1</td>\n",
       "      <td>{'date-parts': [[2022, 2, 28]], 'date-time': '...</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289133</th>\n",
       "      <td>10.1007/978-3-030-87019-5_7</td>\n",
       "      <td>{'date-parts': [[2022, 2, 28]], 'date-time': '...</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480297 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _id  \\\n",
       "54965        10.1016/0168-1702(95)00046-s   \n",
       "49291       10.1016/s0168-1702(01)00432-4   \n",
       "40764       10.1016/s0929-693x(01)00696-0   \n",
       "56200       10.1016/s0165-2478(97)87550-5   \n",
       "31251       10.1016/s0966-842x(00)89018-6   \n",
       "...                                   ...   \n",
       "344664         10.1016/j.ijid.2021.12.146   \n",
       "344665              10.36106/ijar/7000796   \n",
       "344666        10.1016/j.rceng.2021.11.005   \n",
       "344668  10.22541/au.164608823.39016270/v1   \n",
       "289133        10.1007/978-3-030-87019-5_7   \n",
       "\n",
       "                                                  created        date  \n",
       "54965   {'date-parts': [[2002, 7, 25]], 'date-time': '...  2002-07-25  \n",
       "49291   {'date-parts': [[2002, 7, 25]], 'date-time': '...  2002-07-25  \n",
       "40764   {'date-parts': [[2002, 7, 25]], 'date-time': '...  2002-07-25  \n",
       "56200   {'date-parts': [[2002, 7, 25]], 'date-time': '...  2002-07-25  \n",
       "31251   {'date-parts': [[2002, 7, 25]], 'date-time': '...  2002-07-25  \n",
       "...                                                   ...         ...  \n",
       "344664  {'date-parts': [[2022, 2, 28]], 'date-time': '...  2022-02-28  \n",
       "344665  {'date-parts': [[2022, 2, 28]], 'date-time': '...  2022-02-28  \n",
       "344666  {'date-parts': [[2022, 2, 28]], 'date-time': '...  2022-02-28  \n",
       "344668  {'date-parts': [[2022, 2, 28]], 'date-time': '...  2022-02-28  \n",
       "289133  {'date-parts': [[2022, 2, 28]], 'date-time': '...  2022-02-28  \n",
       "\n",
       "[480297 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timeframe of created date\n",
    "sub_df = covid_df[['_id', 'created']]\n",
    "\n",
    "sub_df['date'] = sub_df['created'].apply(lambda x: date_formatting(x))\n",
    "sub_df['date'] = pd.to_datetime(sub_df['date']).dt.to_period('D')\n",
    "sub_df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude non-English articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "    except:\n",
    "        language = 'Error'\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['text'] = covid_df['title'].astype(str) + ' ' + covid_df['abstract'].astype(str) + ' ' + covid_df['pubmed-abstract'].astype(str)\n",
    "covid_df['language'] = covid_df['text'].apply(detect_language)\n",
    "english_covid_df = covid_df.loc[covid_df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414062, 73)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save English COVID articles\n",
    "\n",
    "cols = list(english_covid_df.columns)\n",
    "cols.remove('text')\n",
    "cols.remove('language')\n",
    "english_covid_df[cols].to_csv(OUTPUT_PATH + \"covid_articles.tsv\", sep='\\t', encoding='utf-8', index=False)\n",
    "english_covid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile(r'<[^>]+>')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    cleantext = re.sub('  ', ' ', cleantext)\n",
    "    return cleantext\n",
    "\n",
    "\n",
    "def cleaning_text(text):\n",
    "    \"\"\"\n",
    "        Remove stop-words\n",
    "        No digits\n",
    "        No word length less than 3 \n",
    "        Convert to lowercase\n",
    "    \"\"\"\n",
    "    # remove html tags\n",
    "    cleantext = cleanhtml(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    pos_family = {\n",
    "        'noun': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "        'pron': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
    "        'verb': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "        'adj': ['JJ', 'JJR', 'JJS'],\n",
    "        'adv': ['RB', 'RBR', 'RBS', 'WRB']\n",
    "    }\n",
    "    \n",
    "    regex = r\"\\b[^\\d\\W]+\\b\"\n",
    "    tokens = []\n",
    "    cleantext = cleantext.replace('-', '_')\n",
    "    sentences = nltk.sent_tokenize(cleantext)\n",
    "    \n",
    "    for s in sentences:\n",
    "        words = re.findall(regex, s)\n",
    "        pairs = nltk.pos_tag(words)\n",
    "        for pair in pairs:\n",
    "            w = list(pair)[0] \n",
    "            tag = list(pair)[1]\n",
    "            if w in stopwords: continue\n",
    "            if w.isdigit(): continue\n",
    "            if w.isupper() != True:w = w.lower() \n",
    "            if len(w) <= 3: continue\n",
    "            if tag in pos_family['noun']:\n",
    "                w = lemmatizer.lemmatize(w, 'n')\n",
    "            elif tag in pos_family['pron']: # e.g their, self, what\n",
    "                w = lemmatizer.lemmatize(w)\n",
    "            elif tag in pos_family['verb']: # e.g experienced, based, evaluating, trying, healthcare\n",
    "                w = lemmatizer.lemmatize(w, 'v')\n",
    "            elif tag in pos_family['adj']: # e.g significant, pandemic, clinical, sensitive\n",
    "                w = lemmatizer.lemmatize(w, 'a')\n",
    "            elif tag in pos_family['adv']: #e.g. sore, seriously, alone, nationally\n",
    "                w = lemmatizer.lemmatize(w, 'r')\n",
    "            tokens.append(w)\n",
    "    cleaned_text = ' '.join(tokens)\n",
    " \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_stopwords(text):\n",
    "    \"\"\"\n",
    "        Remove common-words\n",
    "    \"\"\"\n",
    "    stopwords = list(set(nltk.corpus.stopwords.words('english')))\n",
    "    avoiding_words = ['covid_19', 'covid', 'COVID', 'covid_', 'COVID_', 'CORONAVIRUS', \n",
    "                      'SARS_COV_2', 'coronavirus', 'coronaviruses', \n",
    "                      'sars_cov_2', 'conclusion', 'CONCLUSION', 'objective', 'OBJECTIVE', 'ABSTRACT', 'BACKGROUND'\n",
    "                      'abstract', 'background', 'AUTHOR', 'DISCLOSURE', 'author', 'disclosure', 'title', 'TITLE']\n",
    "    stopwords.extend(avoiding_words)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        if word not in stopwords:\n",
    "            new_text.append(word)\n",
    "                \n",
    "    cleaned_text = ' '.join(new_text)\n",
    " \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning part1\n",
    "\n",
    "text_cleaning = lambda x: cleaning_text(x)\n",
    "english_covid_df['cleaned_text'] = english_covid_df['text'].apply(text_cleaning)\n",
    "english_covid_df.drop(columns=['text'], inplace=True)\n",
    "english_covid_df.rename(columns={'cleaned_text':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning part2\n",
    "\n",
    "text_cleaning = lambda x: removing_stopwords(x)\n",
    "english_covid_df['cleaned_text'] = english_covid_df['text'].apply(text_cleaning)\n",
    "english_covid_df.drop(columns=['text'], inplace=True)\n",
    "english_covid_df.rename(columns={'cleaned_text':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop articles after text cleaning\n",
    "\n",
    "We exclude word in the text if the word is a digit, stop-words, or special charater during the text cleaning process. Therefore, some articles remain zero-word after the text cleaning process. We drop these zero-word articles from the corpus before we apply topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is Covid-19?']\n",
      "['COVID-19 – where do we go from here?']\n",
      "['The day after COVID-19']\n",
      "['COVID-19 and the Eye']\n",
      "['Where Is the ID in COVID-19?']\n",
      "['The Day After Covid-19']\n",
      "['Coronavirus and COVID-19']\n",
      "['COVID-19 and the eye']\n",
      "[\"What's new in COVID-19?\"]\n",
      "['NLP for COVID-19']\n",
      "['How Do We End COVID-19?']\n",
      "['The UK and Covid-19']\n",
      "['COVID-19: Where Are We Now?']\n",
      "['The BBC and Covid-19']\n",
      "['COVID-19: the day after']\n",
      "['COVID-19: where do we go from here?']\n",
      "['COVID-19: A New Coronavirus']\n",
      "['COVID-19 – Where should we go now?']\n",
      "['CMR in the Era of COVID-19']\n",
      "['Covid-19 and Covid-1619']\n",
      "['COVID-19: A New Coronavirus']\n",
      "['HIV in the age of COVID-19']\n",
      "['XR in the era of COVID-19']\n",
      "['COVID-19 (A): How Did We Get Here and What Do We Do Now?']\n",
      "['How can we get out of COVID-19?']\n",
      "['COVID-19: is the ACE2 just a foe?']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-Vaccine-Pfizer-Biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['The 12-Lead ECG in COVID-19']\n",
      "['Covid-19-vaccine-Pfizer-BioNTech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-Pfizer-BioNTech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Covid-19-vaccine-pfizer-biontech']\n",
      "['Coronaviruses, COVID-19 and SARS-CoV-2']\n",
      "['Coronavirus, COVID-19 and SARS-CoV-2']\n",
      "['Coronavirus SARS-CoV-2 and Covid-19']\n",
      "['antifungal-treatment-of-mucormycosis-associated-with-covid-19']\n",
      "['SARS-CoV-2, COVID-19, and the Eye']\n",
      "['New Coronavirus COVID-19 (SARS-CoV-2)']\n",
      "['on-the-stabilization-of-the-spread-of-the-coronavirus-covid-19-pandemic-in-the-world']\n",
      "['the-convalescent-serum-for-treatment-of-covid-19-infection-review']\n",
      "['covid-19-in-algeria-chronology-and-evaluation-of-preventive-actions']\n",
      "['clinical-pharmacist-in-a-covid-19-hospital-a-malaysian-experience']\n",
      "['Covid-19-vaccine-Pfizer-BioNTech/mRNA-1273']\n",
      "['Azd-1222/covid-19-vaccine-pfizer-biontech']\n",
      "['national-guidelines-on-management-of-coronavirus-disease-covid-19-in-morocco']\n",
      "['spreading-of-the-novel-coronavirus-covid-19-mathematical-modeling-in-malaysia-perspective']\n",
      "['COVID-19-vaccine-Gamaleya-National-Research-Center-of-Epidemiology-and-Microbiology']\n",
      "['S E C T I O N 5 / What after COVID-19?']\n",
      "['COVID-19-vaccine-Gamaleya-National-Research-Center-of-Epidemiology-and-Microbiology']\n",
      "['Ad26.cov2-s/azd-1222/covid-19-vaccine-pfizer-biontech']\n",
      "['Ad26.cov2-s/covid-19-vaccine-pfizer-biontech/gsk-137173a']\n",
      "['monotherapy-with-lopinavir-ritonavir-or-in-combination-with-interferon-beta-1b-in-patients-with-non-severe-covid-19-disease-a-clinical-case-series']\n",
      "['About coronavirus']\n",
      "['The Coronavirus']\n",
      "['The Coronaviruses']\n",
      "['The Coronavirus:']\n",
      "['What Is a Coronavirus?']\n",
      "['New coronavirus']\n",
      "['TiO2 and the Coronavirus']\n",
      "['JLT and the Coronavirus']\n",
      "['Coronaviruses in the Sea']\n",
      "['The WHO in the Age of the Coronavirus']\n",
      "['More on UFC and the Coronavirus']\n",
      "['Coronaviruses and SARS-COV-2']\n",
      "['New Coronavirus: SARS-COV-2']\n",
      "['SARS-COV-2, can you be over it?']\n",
      "['4CPS-388\\u2005Telepharmacy during SARS-CoV-2']\n",
      "['mRNA-1273-SARS-CoV-2-Impfstoff']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['SARS-COV-2-vaccine-inactivated-Sinovac-Biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['Sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "['Azd-1222/sars-cov-2-vaccine-inactivated-sinovac-biotech']\n",
      "103 of articles are dropped as the cleaned text is null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(413915, 73)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop zero-word articles\n",
    "english_covid_df.reset_index()\n",
    "drop_index = []\n",
    "for index, row in english_covid_df.iterrows():\n",
    "    if len(row['text']) < 3:\n",
    "        print(row['title'])\n",
    "        drop_index.append(index)\n",
    "print(\"{} of articles are dropped as the cleaned text is null\".format(len(drop_index)))\n",
    "preprocessed_df = english_covid_df.drop(drop_index, inplace=False)\n",
    "preprocessed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data preprocessing result\n",
    "preprocessed_df.to_csv(OUTPUT_PATH + \"preprocessed_data(all_data_type).tsv\", sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_venv",
   "language": "python",
   "name": "covid_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
