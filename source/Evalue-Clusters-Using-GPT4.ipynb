{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='debug.log',filemode='w',level=logging.DEBUG, format='%(asctime)s | %(levelname)s | %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input.csv')\n",
    "answers = []\n",
    "current_index = 0\n",
    "MODEL = sys.argv[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '''<probability>0.8</probability>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_map = {\n",
    "    0: \"Pandemic, Experience, Learn, Challenge, Management, Effect, Time, Social, Change, Lesson\",\n",
    "    1: \"Patient, Clinical, Outcome, Cancer, Hospitalized, Care, Mortality, Treatment, Severe, Characteristic\",\n",
    "    2: \"Impact, Lockdown, Economic, Psychological, Economy, India, Market, Industry, Tourism, Global\",\n",
    "    3: \"Health, Mental, Care, Public, Worker, Among, Social, Effect, Crisis, System\",\n",
    "    4: \"Review, Systematic, Literature, Meta-analysis, Scoping, Treatment, Narrative, Report, Effect, Rapid\",\n",
    "    5: \"Infection, Syndrome, Child, Respiratory, Acute, Severe, Risk, Vaccination, Report, Viral\",\n",
    "    6: \"Disease, Severity, Cardiovascular, Infectious, Novel, Chronic, Inflammatory, Child, Outbreak, Model\",\n",
    "    7: \"Vaccine, Vaccination, Response, Hesitancy, mRNA, Development, Variant, Antibody, Among, Safety\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = '''Analyse the following article and determine the probability that this article aligns with a collection of papers that can be represented by a set of important keywords. Evaluate against all the given keywords and provide the reason for the alignment. The order of the keywords represent the order of their priroity. Calculate the alignment by giving higher weight to keywords with higher priority. \n",
    "\n",
    "*Collection*\n",
    "Important keywords: {keywords}. \n",
    "\n",
    "*Return results*\n",
    "Return the probability of the alignment between the publication and the collection. This is an example of the desirable output: \n",
    "{example}\n",
    "\n",
    "*Article*\n",
    "Title: {title} \n",
    "Description: {description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting Script\")\n",
    "client = OpenAI()\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        text = PROMPT.format(example = example, title = row['title'], description = row['abstract'], keywords = keyword_map[row['nmf-topic']])\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": PROMPT.format(example = example, title = row['title'], description = row['abstract'], keywords = keyword_map[row['nmf-topic']])}])\n",
    "\n",
    "        answer = response.choices[0].message.content\n",
    "        current_index +=1\n",
    "        match = re.search(r'<probability>(.*?)</probability>', answer)\n",
    "        print(PROMPT.format(example = example, title = row['title'], description = row['abstract'], keywords = keyword_map[row['nmf-topic']]))\n",
    "        if match:\n",
    "            row['gpt-probability'] = float(match.group(1))\n",
    "        else:\n",
    "            row['gpt-probability'] = 'n/a'\n",
    "        row[MODEL] = answer\n",
    "        row['prompt'] = PROMPT.format(example = example, title = row['title'], description = row['abstract'], keywords = keyword_map[row['nmf-topic']])\n",
    "        answers.append(row)\n",
    "        if current_index % 10 == 0:\n",
    "            logging.info(\"Completed {}\".format(current_index))\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        print(e)\n",
    "logging.info(\"Completed Script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting Write to file\")\n",
    "fdate = datetime.now().strftime('%d%m%Y%H')\n",
    "output_df = pd.DataFrame(answers, columns=['doi','title','abstract','nmf-topic','nmf-topic-coorelation', 'prompt', MODEL, 'gpt-probability'])\n",
    "output_df.to_csv(\"covid-clustering-\" + MODEL + \".csv\", index= False)\n",
    "logging.info(\"Completed Write to file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
